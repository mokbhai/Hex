# AI Client Contract

**Purpose**: Defines the interface for local AI model inference operations.

## Endpoints

### POST /infer/text
Generate text response from AI model.

**Request**:
```json
{
  "model": "string",
  "prompt": "string",
  "maxTokens": 100,
  "temperature": 0.7
}
```

**Response**:
```json
{
  "text": "string",
  "tokensUsed": 42,
  "processingTime": 1.2
}
```

**Error Codes**:
- 400: Invalid request
- 404: Model not found
- 503: Model not loaded

### GET /models
List available downloaded models.

**Response**:
```json
{
  "models": [
    {
      "id": "string",
      "name": "string",
      "capabilities": ["text-generation"]
    }
  ]
}
```

### POST /models/{id}/load
Load a model into memory.

**Response**:
```json
{
  "status": "loaded",
  "memoryUsage": 512000000
}
```

### DELETE /models/{id}/unload
Unload a model from memory.

**Response**:
```json
{
  "status": "unloaded"
}
```